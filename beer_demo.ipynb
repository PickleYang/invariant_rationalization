{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chang87/anaconda3/envs/tf-gpu-14-github-test/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/chang87/anaconda3/envs/tf-gpu-14-github-test/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/chang87/anaconda3/envs/tf-gpu-14-github-test/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/chang87/anaconda3/envs/tf-gpu-14-github-test/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/chang87/anaconda3/envs/tf-gpu-14-github-test/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/chang87/anaconda3/envs/tf-gpu-14-github-test/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/chang87/anaconda3/envs/tf-gpu-14-github-test/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/chang87/anaconda3/envs/tf-gpu-14-github-test/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/chang87/anaconda3/envs/tf-gpu-14-github-test/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/chang87/anaconda3/envs/tf-gpu-14-github-test/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/chang87/anaconda3/envs/tf-gpu-14-github-test/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/chang87/anaconda3/envs/tf-gpu-14-github-test/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "\n",
    "# set gpu\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"1\"\n",
    "\n",
    "# set random seed\n",
    "seed = 7152020\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.compat.v1.set_random_seed(seed)\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = \"1\"\n",
    "\n",
    "from beer import get_beer_datasets, get_beer_annotation\n",
    "from utils import get_pretained_glove\n",
    "from beer_model import InvRNNwithSpanPred\n",
    "from train import train_beer\n",
    "from evaluate import test_beer, validate_beer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parameters:\n",
      "\tASPECT=1\n",
      "\tBASE_DIR=./data/invariant_beer_release\n",
      "\tBATCH_SIZE=500\n",
      "\tDIFF_LAMBDA=2.0\n",
      "\tEMBEDDING_DIM=100\n",
      "\tGLOVE_PATH=./embeddings/glove.6B.100d.txt\n",
      "\tLR=0.001\n",
      "\tMAX_SEQ_LENGTH=300\n",
      "\tNUM_CLASSES=2\n",
      "\tNUM_ENVS=2\n",
      "\tNUM_EPOCHS=50\n",
      "\tNUM_RUN=5\n",
      "\tRATIONALE_LENGTH=20\n",
      "\tRNN_DIM=256\n",
      "\tWORD_THRES=2\n"
     ]
    }
   ],
   "source": [
    "######################\n",
    "# parameters\n",
    "######################\n",
    "class Placeholder:\n",
    "    pass\n",
    "\n",
    "args = Placeholder()\n",
    "\n",
    "# dataset parameters\n",
    "args.aspect = 1\n",
    "args.base_dir = \"./data/invariant_beer_release\"\n",
    "args.max_seq_length = 300\n",
    "args.word_thres = 2\n",
    "args.batch_size = 500\n",
    "\n",
    "# pretrained embeddings\n",
    "args.glove_path = \"./embeddings/glove.6B.100d.txt\"\n",
    "\n",
    "# model parameters\n",
    "args.embedding_dim = 100\n",
    "args.rnn_dim = 256\n",
    "args.num_classes = 2\n",
    "args.num_envs = 2\n",
    "args.rationale_length = 20\n",
    "\n",
    "# learning parameters\n",
    "args.num_epochs = 50\n",
    "args.diff_lambda = 2.\n",
    "args.lr = 1e-3\n",
    "args.num_run = 5\n",
    "\n",
    "print(\"\\nParameters:\")\n",
    "for attr, value in sorted(args.__dict__.items()):\n",
    "    print(\"\\t{}={}\".format(attr.upper(), value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(args):\n",
    "    \"\"\"\n",
    "    Running the model. \n",
    "    \"\"\"\n",
    "    ######################\n",
    "    # load dataset\n",
    "    ######################\n",
    "    data_dir = os.path.join(args.base_dir, \"aspect_%d\" % args.aspect)\n",
    "\n",
    "    args.vocab, D_tr_, D_dev = get_beer_datasets(data_dir, args.max_seq_length, args.word_thres)\n",
    "    D_ann = get_beer_annotation(args.base_dir, args.aspect, args.max_seq_length, args.vocab.word2idx)\n",
    "\n",
    "    D_tr = D_tr_.shuffle(100000).batch(args.batch_size, drop_remainder=False)\n",
    "    D_dev = D_dev.batch(args.batch_size, drop_remainder=False)\n",
    "    D_ann = D_ann.batch(args.batch_size, drop_remainder=False)   \n",
    "    \n",
    "    ######################\n",
    "    # Get pretrained embedding\n",
    "    ######################\n",
    "    args.pretrained_embedding = get_pretained_glove(args.vocab.word2idx, args.glove_path)\n",
    "    \n",
    "    ######################\n",
    "    # build the model\n",
    "    ######################\n",
    "    inv_rnn = InvRNNwithSpanPred(args)\n",
    "    \n",
    "    ######################\n",
    "    # optimizer\n",
    "    ######################\n",
    "    gen_opt = tf.keras.optimizers.Adam(learning_rate=args.lr)\n",
    "    env_inv_opt = tf.keras.optimizers.Adam(learning_rate=args.lr)\n",
    "    env_enable_opt = tf.keras.optimizers.Adam(learning_rate=args.lr)\n",
    "\n",
    "    opts = [gen_opt, env_inv_opt, env_enable_opt]\n",
    "\n",
    "    global_step = 0\n",
    "    \n",
    "    ######################\n",
    "    # learning\n",
    "    ######################\n",
    "    dev_results = []\n",
    "    ann_results = []\n",
    "\n",
    "    for epoch in range(args.num_epochs):\n",
    "        # reshuffle the dataset\n",
    "        D_tr = D_tr_.shuffle(100000).batch(args.batch_size, drop_remainder=False)\n",
    "\n",
    "        global_step = train_beer(D_tr, inv_rnn, opts, global_step, args)\n",
    "\n",
    "        # dev\n",
    "        dev_result = test_beer(D_dev, inv_rnn)\n",
    "        dev_results.append(list(dev_result))\n",
    "\n",
    "        # ann\n",
    "        ann_result = validate_beer(D_ann, inv_rnn)\n",
    "        ann_results.append(list(ann_result))\n",
    "\n",
    "    np_dev_results = np.array(dev_results)\n",
    "    np_ann_results = np.array(ann_results)\n",
    "\n",
    "    # check the best dev result\n",
    "    best_dev_epoch = np.argmax(np_dev_results, axis=0)[0]\n",
    "    best_dev_result = np_dev_results[best_dev_epoch, :]\n",
    "    best_cors_ann_result = np_ann_results[best_dev_epoch, :]\n",
    "    \n",
    "\n",
    "    return best_dev_result, best_cors_ann_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================\n",
      "run: 0\n",
      "=========================\n",
      "Training set: \n",
      "Number of examples 10000\n",
      "Dev set: \n",
      "Number of examples 2000\n",
      "Annotated rationales: 877\n",
      "WARNING:tensorflow:From /home/chang87/anaconda3/envs/tf-gpu-14-github-test/lib/python3.6/site-packages/tensorflow/python/data/util/random_seed.py:58: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "13542 out of 16023 words are covered by the pre-trained embedding.\n",
      "Initialize the embedding from a pre-trained matrix.\n",
      "Initialize the embedding from a pre-trained matrix.\n",
      "Initialize the embedding from a pre-trained matrix.\n",
      "WARNING:tensorflow:From /home/chang87/Workspaces/invariant_rationalization_pvt/beer_model.py:46: The name tf.keras.layers.CuDNNGRU is deprecated. Please use tf.compat.v1.keras.layers.CuDNNGRU instead.\n",
      "\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "=========================\n",
      "run: 1\n",
      "=========================\n",
      "Training set: \n",
      "Number of examples 10000\n",
      "Dev set: \n",
      "Number of examples 2000\n",
      "Annotated rationales: 877\n",
      "13542 out of 16023 words are covered by the pre-trained embedding.\n",
      "Initialize the embedding from a pre-trained matrix.\n",
      "Initialize the embedding from a pre-trained matrix.\n",
      "Initialize the embedding from a pre-trained matrix.\n",
      "=========================\n",
      "run: 2\n",
      "=========================\n",
      "Training set: \n",
      "Number of examples 10000\n",
      "Dev set: \n",
      "Number of examples 2000\n",
      "Annotated rationales: 877\n",
      "13542 out of 16023 words are covered by the pre-trained embedding.\n",
      "Initialize the embedding from a pre-trained matrix.\n",
      "Initialize the embedding from a pre-trained matrix.\n",
      "Initialize the embedding from a pre-trained matrix.\n",
      "=========================\n",
      "run: 3\n",
      "=========================\n",
      "Training set: \n",
      "Number of examples 10000\n",
      "Dev set: \n",
      "Number of examples 2000\n",
      "Annotated rationales: 877\n",
      "13542 out of 16023 words are covered by the pre-trained embedding.\n",
      "Initialize the embedding from a pre-trained matrix.\n",
      "Initialize the embedding from a pre-trained matrix.\n",
      "Initialize the embedding from a pre-trained matrix.\n",
      "=========================\n",
      "run: 4\n",
      "=========================\n",
      "Training set: \n",
      "Number of examples 10000\n",
      "Dev set: \n",
      "Number of examples 2000\n",
      "Annotated rationales: 877\n",
      "13542 out of 16023 words are covered by the pre-trained embedding.\n",
      "Initialize the embedding from a pre-trained matrix.\n",
      "Initialize the embedding from a pre-trained matrix.\n",
      "Initialize the embedding from a pre-trained matrix.\n",
      "----> [Final result] dev inv acc: 0.8225, dev enb acc: 0.8110, The best annotation result: sparsity: 0.1561, precision: 0.4962, recall: 0.4999, f1: 0.4981.\n"
     ]
    }
   ],
   "source": [
    "dev_results = []\n",
    "cors_ann_results = []\n",
    "\n",
    "for run in range(args.num_run):\n",
    "    print(\"=========================\")\n",
    "    print(\"run:\", run)\n",
    "    print(\"=========================\")\n",
    "    \n",
    "    dev_result, ann_result = run_model(args)\n",
    "    \n",
    "    dev_results.append(list(dev_result))\n",
    "    cors_ann_results.append(list(ann_result))\n",
    "    \n",
    "np_dev_results = np.array(dev_results)\n",
    "np_cors_ann_results = np.array(cors_ann_results)\n",
    "\n",
    "best_dev_run = np.argmax(np_dev_results, axis=0)[0]\n",
    "best_dev_result = np_dev_results[best_dev_run, :]\n",
    "best_ann_result = np_cors_ann_results[best_dev_run, :]\n",
    "\n",
    "print(\"{:s} {:s}{:.4f}, {:s}{:.4f}, {:s}{:.4f}, {:s}{:.4f}, {:s}{:.4f}, {:s}{:.4f}.\".format(\n",
    "    \"----> [Final result]\",\n",
    "    \"dev inv acc: \", best_dev_result[0], \n",
    "    \"dev enb acc: \", best_dev_result[1],\n",
    "    \"The best annotation result: sparsity: \", best_ann_result[0], \n",
    "    \"precision: \", best_ann_result[1],\n",
    "    \"recall: \", best_ann_result[2],\n",
    "    \"f1: \", best_ann_result[3]), flush=True)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.771 , 0.7495],\n",
       "       [0.8045, 0.804 ],\n",
       "       [0.8225, 0.811 ],\n",
       "       [0.796 , 0.792 ],\n",
       "       [0.81  , 0.8055]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_dev_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1487807 , 0.12457973, 0.11961722, 0.12204805],\n",
       "       [0.15351497, 0.2655068 , 0.2630426 , 0.26426893],\n",
       "       [0.1561054 , 0.4962234 , 0.49991354, 0.49806166],\n",
       "       [0.15406878, 0.20037106, 0.19922753, 0.19979765],\n",
       "       [0.15633765, 0.4340647 , 0.43794316, 0.4359953 ]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_cors_ann_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
